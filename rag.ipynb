{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8f9ed7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"WARNING: OPENAI_API_KEY not set. Set it with %env or your environment before running API cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from collections import Counter\n",
    "import hashlib\n",
    "import random\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7618433",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Text utilities ----------\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "# ---------- Simple cosine similarity ----------\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-12\n",
    "    return float(np.dot(a, b) / denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e90dc4",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Prompt store (XML) ----------\n",
    "PROMPTS_XML = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<prompts version=\"1.0\">\n",
    "  <prompt id=\"classify_scope.system\"><![CDATA[\n",
    "You are a domain gate for a RAG system.\n",
    "Decide whether the user query is IN SCOPE for one of the allowed DOMAINS, or OUT OF SCOPE.\n",
    "Rules:\n",
    "1) If none of the domains clearly apply, set in_scope=false and domain=null.\n",
    "2) Domain must be one of DOMAINS or null. Never invent domains.\n",
    "3) Be conservative: low confidence => out of scope.\n",
    "Return STRICT JSON with keys: in_scope (bool), domain (string|null), reason (string).\n",
    "  ]]></prompt>\n",
    "\n",
    "  <prompt id=\"classify_scope.user\"><![CDATA[\n",
    "DOMAINS = {DOMAINS}\n",
    "QUERY = {QUERY}\n",
    "  ]]></prompt>\n",
    "\n",
    "  <prompt id=\"generate.system\"><![CDATA[\n",
    "You are a RAG assistant. Use ONLY the provided context.\n",
    "If the question is out of scope, answer: \"I don't have information on this topic.\"\n",
    "Keep answers concise (â‰¤ 6 sentences).\n",
    "When evidence exists, reference sources in-text using [doc_id] markers that match citations.\n",
    "Do not fabricate links or content beyond the given context.\n",
    "  ]]></prompt>\n",
    "\n",
    "  <prompt id=\"generate.user\"><![CDATA[\n",
    "Question: {QUERY}\n",
    "\n",
    "Context:\n",
    "{CONTEXT}\n",
    "  ]]></prompt>\n",
    "</prompts>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c380e",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class _SafeDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        return \"{\" + key + \"}\"\n",
    "\n",
    "\n",
    "class PromptStore:\n",
    "    def __init__(self, xml_text: str):\n",
    "        self._prompts: Dict[str, str] = {}\n",
    "        self._load(xml_text)\n",
    "\n",
    "    def _load(self, xml_text: str):\n",
    "        root = ET.fromstring(xml_text)\n",
    "        for node in root.findall(\".//prompt\"):\n",
    "            pid = node.attrib.get(\"id\")\n",
    "            if not pid:\n",
    "                continue\n",
    "            text = (node.text or \"\").strip()\n",
    "            self._prompts[pid] = text\n",
    "\n",
    "    def get(self, prompt_id: str) -> str:\n",
    "        if prompt_id not in self._prompts:\n",
    "            raise KeyError(f\"Prompt id not found: {prompt_id}\")\n",
    "        return self._prompts[prompt_id]\n",
    "\n",
    "    def render(self, prompt_id: str, **kwargs) -> str:\n",
    "        return self.get(prompt_id).format_map(_SafeDict(**kwargs))\n",
    "\n",
    "\n",
    "prompts = PromptStore(PROMPTS_XML)\n",
    "\n",
    "print(\"Cell 1 ready: utils + PromptStore loaded with prompt ids\",\n",
    "list(prompts._prompts.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e5a6e",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "EMBED_MODEL = os.getenv(\"OPENAI_MODEL_EMBED\", \"text-embedding-3-small\")  # 1536 dims\n",
    "\n",
    "def _l2_normalize_rows(X: np.ndarray) -> np.ndarray:\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "    return X / norms\n",
    "\n",
    "def embed_texts_openai(texts: List[str], model: str = EMBED_MODEL) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns a 2D numpy array [n_texts, dim], L2-normalized.\n",
    "    \"\"\"\n",
    "    resp = client.embeddings.create(model=model, input=texts)\n",
    "    vecs = [d.embedding for d in resp.data]\n",
    "    X = np.array(vecs, dtype=np.float32)\n",
    "    return _l2_normalize_rows(X)\n",
    "\n",
    "def embed_text_openai(text: str, model: str = EMBED_MODEL) -> np.ndarray:\n",
    "    return embed_texts_openai([text], model=model)[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
